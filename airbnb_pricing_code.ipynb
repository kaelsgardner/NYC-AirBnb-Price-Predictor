{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load the dfset\n",
    "df = pd.read_csv('AB_NYC_2019.csv')\n",
    "\n",
    "# Select columns of interest (Complication_risk and the 15 independent variables)\n",
    "columns_of_interest = [\n",
    "    'price', 'latitude', 'longitude', 'room_type', 'minimum_nights', 'number_of_reviews', 'reviews_per_month',\n",
    "    'calculated_host_listings_count', 'availability_365', 'neighbourhood_group', 'neighbourhood'\n",
    "]\n",
    "\n",
    "df = df[columns_of_interest]\n",
    "\n",
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Check for null values\n",
    "null_counts = df.isnull().sum()\n",
    "# print(\"Null value counts:\\n\", null_counts)\n",
    "# Since the only nulls are in 'reviews_per_month' and they're null because \n",
    "# they don't have any reviews yet, we'll replace these nulls with 0\n",
    "df['reviews_per_month'].fillna(0, inplace=True)\n",
    "\n",
    "# Handle outliers for numerical df using RobustScaler\n",
    "numerical_columns = ['price', 'latitude', 'longitude', 'minimum_nights', 'number_of_reviews', 'reviews_per_month',\n",
    "    'calculated_host_listings_count', 'availability_365']\n",
    "\n",
    "def handle_outliers(df, col, lower_percentile=0.01, upper_percentile=0.99):\n",
    "    lower_bound = df[col].quantile(lower_percentile)\n",
    "    upper_bound = df[col].quantile(upper_percentile)\n",
    "    df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])\n",
    "    df[col] = np.where(df[col] > upper_bound, upper_bound, df[col])\n",
    "    return df\n",
    "\n",
    "for col in numerical_columns:\n",
    "    df = handle_outliers(df, col)\n",
    "\n",
    "#print(\"Preprocessed df:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "cat_cols = ['room_type', 'neighbourhood_group', 'neighbourhood']\n",
    "one_hot_encoded_data = pd.get_dummies(df[cat_cols], prefix=cat_cols, dtype=int)\n",
    "df_dropped = df.drop(columns=cat_cols)\n",
    "df_encoded = pd.concat([df_dropped, one_hot_encoded_data], axis=1)\n",
    "df_encoded.to_csv('cleaned_AB_NYC_2019.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add constant for intercept\n",
    "X = sm.add_constant(df_encoded.drop(columns='price'))\n",
    "\n",
    "# Dependent variable\n",
    "y = df_encoded['price']\n",
    "\n",
    "# Convert DataFrame to NumPy array\n",
    "X_array = X.to_numpy()\n",
    "y_array = y.to_numpy()\n",
    "\n",
    "# Fit the initial model\n",
    "initial_model = sm.OLS(y_array, X_array).fit()\n",
    "\n",
    "# Display model summary\n",
    "print(initial_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_elimination(X, y, significance_level=0.05):\n",
    "    while True:\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        max_p_value = model.pvalues.max()\n",
    "        if max_p_value > significance_level:\n",
    "            max_p_var_label = model.pvalues.idxmax()\n",
    "            print(\"Max p-value variable label:\", max_p_var_label)\n",
    "            X = X.drop(max_p_var_label, axis=1)\n",
    "            print(\"Dropped variable:\", max_p_var_label)\n",
    "        else:\n",
    "            break\n",
    "    return model\n",
    "\n",
    "reduced_model = backward_elimination(X, y)\n",
    "print(reduced_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for the reduced model\n",
    "reduced_residuals = reduced_model.resid\n",
    "\n",
    "# Calculate the residual standard error (RSE)\n",
    "rse = np.sqrt(np.sum(reduced_residuals ** 2) / (len(y) - reduced_model.df_model - 1))\n",
    "print(\"Residual Standard Error:\", rse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a residual plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.residplot(x=reduced_model.fittedvalues, y=reduced_residuals, lowess=True, line_kws={'color': 'red'})\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.xlabel(\"Fitted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
